{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import feather\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sktime.datasets import load_from_tsfile_to_dataframe\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the frames to store information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['Adiac', 'Fish', 'OliveOil', 'Phoneme', 'ShapesAll', 'SwedishLeaf', 'WordSynonyms']\n",
    "\n",
    "# row corresponds to classifier, col to dataset\n",
    "accuracy = pd.DataFrame(columns=datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbrRuns = 1\n",
    "\n",
    "classifiers = ['RF_sumCl', \n",
    "               'RF_sklearn', \n",
    "               'RF_catch22',\n",
    "               'RF_kats',\n",
    "               'RF_tsfeatures',\n",
    "               'RF_tsfel',\n",
    "               'RF_tsfresh']\n",
    "\n",
    "Adiac_pred        = pd.DataFrame(columns=classifiers)\n",
    "Fish_pred         = pd.DataFrame(columns=classifiers)\n",
    "OliveOil_pred     = pd.DataFrame(columns=classifiers)\n",
    "Phoneme_pred      = pd.DataFrame(columns=classifiers)\n",
    "ShapesAll_pred    = pd.DataFrame(columns=classifiers)\n",
    "SwedishLeaf_pred  = pd.DataFrame(columns=classifiers)\n",
    "WordSynonyms_pred = pd.DataFrame(columns=classifiers)\n",
    "\n",
    "predictionFrames = [Adiac_pred,\n",
    "                    Fish_pred,\n",
    "                    OliveOil_pred,\n",
    "                    Phoneme_pred,\n",
    "                    ShapesAll_pred,\n",
    "                    SwedishLeaf_pred,\n",
    "                    WordSynonyms_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting with SKTIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sktime.classification.feature_based import SummaryClassifier\n",
    "\n",
    "sklearn_classifier = RandomForestClassifier()\n",
    "sc_classifier       = SummaryClassifier(estimator=sklearn_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score2 = []\n",
    "\n",
    "\n",
    "for dataset, i in zip(datasets, range(len(predictionFrames))):\n",
    "    print(dataset)\n",
    "    \n",
    "    tmpScores = []\n",
    "    \n",
    "    # load training data\n",
    "    X_train, y_train = load_from_tsfile_to_dataframe('data/' + dataset + '_TRAIN.ts')\n",
    "\n",
    "    # load test data\n",
    "    X_test, y_test = load_from_tsfile_to_dataframe('data/' + dataset + '_TEST.ts')\n",
    "    \n",
    "    ############################\n",
    "    # sktime - SummaryClassifier\n",
    "    \n",
    "    for h in range(nbrRuns):\n",
    "    \n",
    "        if dataset == 'Phoneme':\n",
    "            tmpScores.append(np.nan)\n",
    "            continue\n",
    "        else:\n",
    "            sc_classifier.fit(X_train, y_train)\n",
    "            tmpScores.append(sc_classifier.score(X_test, y_test))\n",
    "    \n",
    "    #print(tmpScores)\n",
    "    score2.append(max(tmpScores))\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy.loc[0] = score2\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKLEARN - basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFrame(dataset, labels):\n",
    "    \n",
    "    # stores series \n",
    "    finalFrame = pd.DataFrame()\n",
    "    \n",
    "    for row in dataset.iterrows():\n",
    "        finalFrame = pd.concat([finalFrame, row[1].values[0].to_frame().T], ignore_index=True)\n",
    "    \n",
    "    # adds labels at the end of the frame\n",
    "    finalFrame['label'] = [int(i) for i in labels]\n",
    "\n",
    "    return finalFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbrRuns = 20\n",
    "score3 = []\n",
    "\n",
    "for dataset, i in zip(datasets, range(len(predictionFrames))):\n",
    "    \n",
    "    tmpScores = []\n",
    "    \n",
    "    # load training data\n",
    "    X_train, y_train = load_from_tsfile_to_dataframe('data/' + dataset + '_TRAIN.ts')\n",
    "    trainData = getFrame(X_train, y_train)\n",
    "\n",
    "    # load test data\n",
    "    X_test, y_test = load_from_tsfile_to_dataframe('data/' + dataset + '_TEST.ts')\n",
    "    testData = getFrame(X_test, y_test)\n",
    "    \n",
    "    for _ in range(nbrRuns):\n",
    "        \n",
    "        sklearn_classifier.fit(trainData.iloc[:, :-1], trainData['label'])\n",
    "        tmpScores.append(sklearn_classifier.score(testData.iloc[:, :-1], testData['label']))\n",
    "        \n",
    "    #print(tmpScores)\n",
    "    score3.append(max(tmpScores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy.loc[1] = score3\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKLEARN x Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catch22    = pd.read_feather('featureFrames/output_catch22.feather')\n",
    "kats       = pd.read_feather('featureFrames/output_kats.feather')\n",
    "tsfeatures = pd.read_feather('featureFrames/test.feather')\n",
    "tsfel      = pd.read_feather('featureFrames/output_tsfel.feather')\n",
    "tsfresh    = pd.read_feather('featureFrames/output_tsfresh.feather')\n",
    "\n",
    "extractors = [catch22,\n",
    "              kats,\n",
    "              tsfeatures,\n",
    "              tsfel,\n",
    "              tsfresh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 2\n",
    "\n",
    "for ex, name in zip(extractors, classifiers[-5:]) :\n",
    "    scoreX = []\n",
    "    \n",
    "    for dataset, i in zip(datasets, range(len(predictionFrames))):\n",
    "        \n",
    "        train = ex.loc[(ex['data'] == dataset) & (ex['set'] == 'train')]\n",
    "        test  = ex.loc[(ex['data'] == dataset) & (ex['set'] == 'test')]\n",
    "        \n",
    "        tmpScores = []\n",
    "        \n",
    "        for _ in range(nbrRuns):\n",
    "        \n",
    "            sklearn_classifier.fit(train.iloc[:, :-3], train['label'])\n",
    "            tmpScores.append(sklearn_classifier.score(test.iloc[:, :-3], test['label']))\n",
    "        \n",
    "        scoreX.append(max(tmpScores))\n",
    "    \n",
    "    accuracy.loc[j] = scoreX\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old results with 1 run \n",
    "# accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPerDataset(axes, y_pos, nbrPlots, df):\n",
    "    \n",
    "    for c in range(nbrPlots):\n",
    "        \n",
    "        axes[c].set_title(df.columns[c])\n",
    "        axes[c].set_xlabel('Classifier')\n",
    "        axes[c].set_ylabel('Accuracy')\n",
    "        \n",
    "        # Create bars\n",
    "        axes[c].bar(y_pos, df.iloc[:, c], color='maroon')\n",
    "        \n",
    "        #\n",
    "        axes[c].set_xticks(y_pos, classifiers, rotation='vertical')\n",
    "    \n",
    "    \n",
    "def plotPerClassifier(axes, y_pos, nbrPlots, df):\n",
    "    \n",
    "    for c in range(nbrPlots):\n",
    "        \n",
    "        axes[c].set_title(classifiers[c])\n",
    "        axes[c].set_xlabel('Dataset')\n",
    "        axes[c].set_ylabel('Accuracy')\n",
    "        \n",
    "        # Create bars\n",
    "        axes[c].bar(y_pos, df.iloc[c], color='maroon')\n",
    "        \n",
    "        #\n",
    "        axes[c].set_xticks(y_pos, datasets, rotation='vertical') \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotAccuracy(df, perDataset = True):\n",
    "    \n",
    "    cols = 3\n",
    "    \n",
    "    if perDataset:\n",
    "        nbrPlots = len(df.columns)\n",
    "        y_pos    = np.arange(len(df))\n",
    "    else:\n",
    "        nbrPlots = len(df)\n",
    "        y_pos    = np.arange(len(df.columns))\n",
    "    \n",
    "    rows = int(np.ceil(nbrPlots/cols))\n",
    "    \n",
    "    fig, ax = plt.subplots(rows, cols, figsize=(30, 30))\n",
    "    # using padding\n",
    "    fig.tight_layout(pad=14.0)\n",
    "    \n",
    "    axes = ax.flatten()\n",
    "    \n",
    "    if perDataset:\n",
    "        plotPerDataset(axes, y_pos, nbrPlots, df)\n",
    "    else:\n",
    "        plotPerClassifier(axes, y_pos, nbrPlots, df)\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotAccuracy(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot for each classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotAccuracy(accuracy, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9d800c14abb2bd109b7479fe8830174a66f0a4a77373f77c2c7334932e1a4922"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
