{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import feather\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilityFuncs import get_problematic_features\n",
    "from utilityFuncs import remove_problematic_datasets\n",
    "from utilityFuncs import zScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load calculated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fullFeatMat = feather.read_dataframe('data/EmpFeatMat.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove bad features and bad IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt1, goodIDs1 = remove_problematic_datasets(fullFeatMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Norm the values by each feature for each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt2 = pd.DataFrame()\n",
    "\n",
    "for method in filt1['method'].unique():\n",
    "\n",
    "    methodFrame = filt1[filt1['method'] == method]\n",
    "    normedFrame = methodFrame.groupby('names').apply(zScore)\n",
    "    \n",
    "    filt2 = pd.concat([filt2, normedFrame], ignore_index=True)\n",
    "    \n",
    "filt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store to use for PCA\n",
    "filt2.to_feather('data/fullFeatMatFilt.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now adding a column called _comb_id_ which stores the method name combined with the feature name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt2['comb_id'] = filt2.apply(lambda row: row['method'] + '_' + row['names'], axis=1)\n",
    "\n",
    "del filt1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step: take every possible combination of 2 methods and calculate the spearman correlation between all features of the two methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a list with all the methods used and get all the possible combinations\n",
    "# take every possible combination of 2 methods and calculate the spearman correlation between all features of the two methods\n",
    "methods = filt2['method'].unique()\n",
    "methodCombinations = list(itertools.combinations(methods, r=2))\n",
    "\n",
    "i = 0\n",
    "\n",
    "# compute the spearman correlation of each method combination\n",
    "for combination in methodCombinations:\n",
    "    \n",
    "    print('Doing: ', combination)\n",
    "    \n",
    "    corrDF = pd.DataFrame(columns=['method1', 'method2', 'feat1', 'feat2', 'corr'])\n",
    "    \n",
    "    # stores the feature names of method 1\n",
    "    frame1 = pd.pivot_table(filt2[filt2['method'] == combination[0]], index=['id'], columns=['comb_id'])\n",
    "    frame2 = pd.pivot_table(filt2[filt2['method'] == combination[1]], index=['id'], columns=['comb_id'])\n",
    "    \n",
    "    # stores all the correlations between each pair of features\n",
    "    allCorr = pd.concat([frame1, frame2], axis=1).corr(method='spearman').filter(frame2.columns).filter(frame1.columns, axis=0)\n",
    "    \n",
    "    # having the correlations in on column, the feature names as indeces\n",
    "    tmpDF = allCorr.stack()\n",
    "    \n",
    "    # rename indeces and column to be able to reset the index\n",
    "    tmpDF.index.names = [None, 'feat1', 'feat2']\n",
    "    tmpDF.columns = ['corr']\n",
    "    corrDF = tmpDF.reset_index().iloc[: , 1:]\n",
    "    \n",
    "    # adds the method names\n",
    "    l = len(corrDF)\n",
    "    corrDF.insert(loc=0, column='method2', value=l * [combination[1]])\n",
    "    corrDF.insert(loc=0, column='method1', value=l * [combination[0]])\n",
    "    \n",
    "    #corrDF.to_feather('corrMatsNorm/corrMat' + str(i) + '.feather')\n",
    "    corrDF.to_feather('corrMats/corrMat' + str(i) + '.feather')\n",
    "    i += 1\n",
    "\n",
    "print('\\nDone.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
