{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "import feather\n",
    "import scipy.stats as stats\n",
    "import itertools\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sktime.datasets import load_from_tsfile_to_dataframe\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from featureExtraction import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['GlobalClimate', 'HumidityHouse',\n",
    "            'HungaryChickenpox', 'IstanbulStockExchange', \n",
    "            'ParkingBirmingham', 'PedalMe']\n",
    "\n",
    "#errors = pd.DataFrame(columns=datasets)\n",
    "badIDs = []\n",
    "\n",
    "\n",
    "plain = []\n",
    "for dataset in datasets:\n",
    "    \n",
    "    plain.append(pd.read_feather('data/' + dataset + '.feather'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CATCH22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "\n",
    "for frame, dataset in zip(plain,datasets):\n",
    "    print(dataset)\n",
    "    \n",
    "    # exclude last element of the series\n",
    "    X = frame.iloc[:,:-4].copy()\n",
    "    info = frame.iloc[:,-4:].copy()\n",
    "    info.columns = ['y', 'ind', 'data', 'set']\n",
    "    \n",
    "    features = Catch22.transform(X)\n",
    "    f = pd.concat([features, info], axis=1)\n",
    "    \n",
    "    df = pd.concat([df, f], ignore_index=True)\n",
    "\n",
    "# replace infinite values with NaN\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# remove features with more than 10% NaN\n",
    "k = len(df.loc[0])\n",
    "\n",
    "output_catch22 = df.drop(df.columns[df.apply(lambda col: (col.isnull().sum() / len(df)) > 0.1)], axis=1)\n",
    "\n",
    "print('\\n')\n",
    "print('# bad features = ', k, ' - ', len(output_catch22.loc[0]))\n",
    "\n",
    "\n",
    "schlechteIDs = output_catch22[output_catch22.isna().any(axis=1)].index.values\n",
    "badIDs.append(schlechteIDs)\n",
    "\n",
    "print('Bad IDs: ', schlechteIDs)\n",
    "output_catch22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for frame, dataset in zip(plain,datasets):\n",
    "    print(dataset)\n",
    "    \n",
    "    # exclude last element of the series\n",
    "    X = frame.iloc[:,:-4].copy()\n",
    "    info = frame.iloc[:,-4:].copy()\n",
    "    info.columns = ['y', 'ind', 'data', 'set']\n",
    "    \n",
    "    features = Kats.transform(X)\n",
    "    features = pd.concat([features, info], axis=1)\n",
    "    \n",
    "    df = pd.concat([df, features], ignore_index=True)\n",
    "\n",
    "# replace infinite values with NaN\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    \n",
    "# remove features with more than 10% NaN\n",
    "k = len(df.loc[0])\n",
    "output_kats = df.drop(df.columns[df.apply(lambda col: (col.isnull().sum() / len(df)) > 0.1)], axis=1)\n",
    "\n",
    "print('\\n')\n",
    "print('# bad features = ', k, ' - ', len(output_kats.loc[0]))\n",
    "\n",
    "\n",
    "schlechteIDs = output_kats[output_kats.isna().any(axis=1)].index.values\n",
    "badIDs.append(schlechteIDs)\n",
    "\n",
    "print('Bad IDs: ', schlechteIDs)\n",
    "output_kats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TSFEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "\n",
    "for frame, dataset in zip(plain,datasets):\n",
    "    print(dataset)\n",
    "    \n",
    "    # exclude last element of the series\n",
    "    X = frame.iloc[:,:-4].copy()\n",
    "    info = frame.iloc[:,-4:].copy()\n",
    "    info.columns = ['y', 'ind', 'data', 'set']\n",
    "    \n",
    "    features = TSFeatures.transform(X)\n",
    "    features = pd.concat([features, info], axis=1)\n",
    "    \n",
    "    df = pd.concat([df, features], ignore_index=True)\n",
    "    \n",
    "# replace infinite values with NaN\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# remove features with more than 10% NaN\n",
    "k = len(df.loc[0])\n",
    "output_tsfeatures = df.drop(df.columns[df.apply(lambda col: (col.isnull().sum() / len(df)) > 0.1)], axis=1)\n",
    "\n",
    "print('\\n')\n",
    "print('# bad features = ', k, ' - ', len(output_tsfeatures.loc[0]))\n",
    "\n",
    "\n",
    "schlechteIDs = output_tsfeatures[output_tsfeatures.isna().any(axis=1)].index.values\n",
    "badIDs.append(schlechteIDs)\n",
    "\n",
    "print('Bad IDs: ', schlechteIDs)\n",
    "output_tsfeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TSFEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "\n",
    "for frame, dataset in zip(plain,datasets):\n",
    "    print(dataset)\n",
    "    \n",
    "    # exclude last element of the series\n",
    "    X = frame.iloc[:,:-4].copy()\n",
    "    info = frame.iloc[:,-4:].copy()\n",
    "    info.columns = ['y', 'ind', 'data', 'set']\n",
    "    \n",
    "    features = TSFel.transform(X)\n",
    "    features = pd.concat([features, info], axis=1)\n",
    "    \n",
    "    df = pd.concat([df, features], ignore_index=True)\n",
    "    \n",
    "# replace infinite values with NaN\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# remove features with more than 10% NaN\n",
    "k = len(df.loc[0])\n",
    "output_tsfel = df.drop(df.columns[df.apply(lambda col: (col.isnull().sum() / len(df)) > 0.1)], axis=1)\n",
    "\n",
    "print('\\n')\n",
    "print('# bad features = ', k, ' - ', len(output_tsfel.loc[0]))\n",
    "\n",
    "\n",
    "schlechteIDs = output_tsfel[output_tsfel.isna().any(axis=1)].index.values\n",
    "badIDs.append(schlechteIDs)\n",
    "\n",
    "print('Bad IDs: ', schlechteIDs)\n",
    "output_tsfel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TSFRESH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "\n",
    "for frame, dataset in zip(plain,datasets):\n",
    "    print(dataset)\n",
    "    \n",
    "    # exclude last element of the series\n",
    "    X = frame.iloc[:,:-4].copy()\n",
    "    info = frame.iloc[:,-4:].copy()\n",
    "    info.columns = ['y', 'ind', 'data', 'set']\n",
    "    \n",
    "    features = TSFresh.transform(X)\n",
    "    features = pd.concat([features, info], axis=1)\n",
    "    \n",
    "    df = pd.concat([df, features], ignore_index=True)\n",
    "    \n",
    "# replace infinite values with NaN\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# remove features with more than 10% NaN\n",
    "k = len(df.loc[0])\n",
    "output_tsfresh = df.drop(df.columns[df.apply(lambda col: (col.isnull().sum() / len(df)) > 0.1)], axis=1)\n",
    "\n",
    "print('\\n')\n",
    "print('# bad features = ', k, ' - ', len(output_tsfresh.loc[0]))\n",
    "\n",
    "\n",
    "schlechteIDs = output_tsfresh[output_tsfresh.isna().any(axis=1)].index.values\n",
    "badIDs.append(schlechteIDs)\n",
    "\n",
    "print('Bad IDs: ', schlechteIDs)\n",
    "output_tsfresh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [output_catch22,\n",
    "          output_kats,\n",
    "          output_tsfeatures,\n",
    "          output_tsfel,\n",
    "          output_tsfresh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in frames:\n",
    "    frame.replace(np.nan, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in frames:\n",
    "    print(frame.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_catch22.to_feather('data/output_catch22.feather')\n",
    "output_kats.to_feather('data/output_kats.feather')\n",
    "output_tsfeatures.to_feather('data/output_tsfeatures.feather')\n",
    "output_tsfel.to_feather('data/output_tsfel.feather')\n",
    "output_tsfresh.to_feather('data/output_tsfresh.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list with unique values that contain the indices to be removed\n",
    "toRemove = list(set([item for sublist in badIDs for item in sublist]))\n",
    "toRemove.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe containing information on 'ind', 'data' and 'set' for the series to be removed \n",
    "bf = output_catch22.iloc[toRemove][['ind', 'data', 'set']].copy()\n",
    "\n",
    "for data, frame in zip(datasets, plain):\n",
    "    \n",
    "    # first remove the bad ones in the training set\n",
    "    badTrainSets = bf.loc[(bf['data'] == data) & (bf['set'] == 'train')]['ind'].values\n",
    "    frame.drop(frame.loc[(frame['ind'].isin(badTrainSets)) & (frame['set'] == 'train')].index, axis=0, inplace=True)\n",
    "    \n",
    "    # the remove the bad ones from the testing set\n",
    "    badTestSets = bf.loc[(bf['data'] == data) & (bf['set'] == 'test')]['ind'].values\n",
    "    frame.drop(frame.loc[(frame['ind'].isin(badTestSets)) & (frame['set'] == 'test')].index, axis=0, inplace=True)\n",
    "    \n",
    "    # reset index\n",
    "    frame.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # save file\n",
    "    frame.to_feather('data/' + data +'_plain.feather')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [output_catch22,\n",
    "                 output_kats,\n",
    "                 output_tsfeatures,\n",
    "                 output_tsfel,\n",
    "                 output_tsfresh].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the bad series from each feature frame\n",
    "featureFrames = [output_catch22,\n",
    "                 output_kats,\n",
    "                 output_tsfeatures,\n",
    "                 output_tsfel,\n",
    "                 output_tsfresh]\n",
    "\n",
    "for frame in featureFrames:\n",
    "    frame.drop(toRemove, axis=0, inplace=True)\n",
    "    frame.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "output_catch22.to_feather('featureFrames/output_catch22.feather')\n",
    "output_kats.to_feather('featureFrames/output_kats.feather')\n",
    "output_tsfeatures.to_feather('featureFrames/output_tsfeatures.feather')\n",
    "output_tsfel.to_feather('featureFrames/output_tsfel.feather')\n",
    "output_tsfresh.to_feather('featureFrames/output_tsfresh.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9d800c14abb2bd109b7479fe8830174a66f0a4a77373f77c2c7334932e1a4922"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
